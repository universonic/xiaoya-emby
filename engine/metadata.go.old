package engine

import (
	"bytes"
	"database/sql"
	"fmt"
	"io"
	"log"
	"math/rand"
	"net/http"
	"net/url"
	"os"
	"path/filepath"
	"runtime"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/PuerkitoBio/goquery"
	_ "github.com/mattn/go-sqlite3"
)

const (
	scanListFile = ".scan.list.gz"
	timeout      = 30 * time.Second
	filePerm     = 0644
	dirPerm      = 0755
)

var (
	// 全局定义常量及初始值，与 Python 代码中对应
	sPathsAll = []string{
		"115/",
		"PikPak/",
		"动漫/",
		"每日更新/",
		"电影/",
		"电视剧/",
		"纪录片/",
		"纪录片（已刮削）/",
		"综艺/",
		"音乐/",
		"📺画质演示测试（4K，8K，HDR，Dolby）/",
	}
	sPaths = []string{
		"115/",
		"每日更新/",
		"纪录片（已刮削）/",
		"音乐/",
		"综艺/",
	}
	sPool = []string{
		"https://emby.xiaoya.pro/",
		"https://icyou.eu.org/",
		"https://emby.8.net.co/",
		"https://emby.raydoom.tk/",
		"https://emby.kaiserver.uk/",
		"https://embyxiaoya.laogl.top/",
		"https://emby-data.poxi1221.eu.org/",
		"https://emby-data.ermaokj.cn/",
		"https://emby-data.bdbd.fun/",
		"https://emby-data.wwwh.eu.org/",
		"https://emby-data.ymschh.top/",
		"https://emby-data.wx1.us.kg/",
		"https://emby-data.r2s.site/",
		"https://emby-data.neversay.eu.org/",
		"https://emby-data.800686.xyz/",
	}
	sFolder = []string{".sync"}
	sExt    = []string{".ass", ".srt", ".ssa"}
)

type Metadata struct {
	URL       string
	FileName  string
	Timestamp int64
	FileSize  int64
	ETag      string
}

func pickAPoolMember(urls []string) string {
	rand.Shuffle(len(urls), func(i, j int) { urls[i], urls[j] = urls[j], urls[i] })

	client := &http.Client{Timeout: timeout}
	for _, member := range urls {
		if isValidPoolMember(member, client) {
			log.Printf("[INFO] Selected mirror: %s", member)
			return member
		}
	}
	return ""
}

func isValidPoolMember(url string, client *http.Client) bool {
	req, err := http.NewRequest("GET", url, nil)
	if err != nil {
		log.Printf("[ERROR] creating request for %s: %v", url, err)
		return false
	}
	req.Header.Set("User-Agent", GlobalUserAgent)
	resp, err := client.Do(req)
	if err != nil {
		log.Printf("[ERROR] accessing %s: %v", url, err)
		return false
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		log.Printf("[ERROR] status for %s: %d", url, resp.StatusCode)
		return false
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		log.Printf("[ERROR] reading body from %s: %v", url, err)
		return false
	}

	return strings.Contains(string(body), "每日更新")
}

func fetchHTML(urlStr string, client *http.Client) (string, error) {
	req, err := http.NewRequest("GET", urlStr, nil)
	if err != nil {
		return "", err
	}
	req.Header.Set("User-Agent", GlobalUserAgent)
	resp, err := client.Do(req)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("status code %d", resp.StatusCode)
	}

	bodyBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", err
	}
	return string(bytes.TrimSpace(bodyBytes)), nil
}

func resolveURL(base, ref string) string {
	baseURL, err := url.Parse(base)
	if err != nil {
		return ""
	}
	refURL, err := url.Parse(ref)
	if err != nil {
		return ""
	}
	return baseURL.ResolveReference(refURL).String()
}

func parseURL(urlStr string, client *http.Client) ([]Metadata, []string, error) {
	html, err := fetchHTML(urlStr, client)
	if err != nil {
		return nil, nil, err
	}

	doc, err := goquery.NewDocumentFromReader(strings.NewReader(html))
	if err != nil {
		return nil, nil, err
	}

	var files []Metadata
	var directories []string

	doc.Find("a").Each(func(i int, s *goquery.Selection) {
		href, exists := s.Attr("href")
		if !exists {
			return
		}

		if isValidFileLink(href) {
			processFileLink(urlStr, href, s, &files)
		} else if isValidDirectoryLink(href) {
			processDirectoryLink(urlStr, href, &directories)
		}
	})

	return files, directories, nil
}

func isValidFileLink(href string) bool {
	return href != "../" && !strings.HasSuffix(href, "/") &&
		!strings.HasSuffix(href, "txt") && href != "scan.list"
}

func isValidDirectoryLink(href string) bool {
	return href != "../" && !strings.HasSuffix(strings.ToLower(href), ".txt")
}

func processFileLink(baseURL, href string, s *goquery.Selection, files *[]Metadata) {
	absLink := resolveURL(baseURL, href)
	parsedURL, err := url.Parse(absLink)
	if err != nil {
		log.Printf("[ERROR] Failed to parse URL: %s", absLink)
		return
	}

	filename, err := url.PathUnescape(parsedURL.Path)
	if err != nil {
		filename = parsedURL.Path
	}

	timestampStr, filesizeStr := extractFileInfo(s)
	if timestampStr == "" || filesizeStr == "" {
		return
	}

	t, err := time.Parse("02-Jan-2006 15:04", timestampStr)
	if err != nil {
		log.Printf("[ERROR] Failed to parse timestamp %s: %v", timestampStr, err)
		return
	}

	filesize, err := strconv.ParseInt(filesizeStr, 10, 64)
	if err != nil {
		log.Printf("[ERROR] Failed to parse filesize %s: %v", filesizeStr, err)
		return
	}

	*files = append(*files, Metadata{
		URL:       absLink,
		FileName:  filename,
		Timestamp: t.Unix(),
		FileSize:  filesize,
	})
}

func extractFileInfo(s *goquery.Selection) (string, string) {
	node := s.Get(0)
	var siblingText string

	if node.NextSibling != nil {
		siblingText = strings.TrimSpace(node.NextSibling.Data)
	}

	if siblingText == "" {
		siblingText = strings.TrimSpace(s.Parent().Text())
		siblingText = strings.Replace(siblingText, s.Text(), "", 1)
	}

	fields := strings.Fields(siblingText)
	if len(fields) < 3 {
		log.Printf("[ERROR] Not enough fields in sibling text")
		return "", ""
	}

	return fields[0] + " " + fields[1], fields[2]
}

func processDirectoryLink(baseURL, href string, directories *[]string) {
	absLink := resolveURL(baseURL, href)
	*directories = append(*directories, absLink)
}

// needDownload checks if a file needs to be downloaded based on its existence, size, and timestamp.
func needDownload(file Metadata, media string, nfo bool) bool {
	filePath := filepath.Join(media, file.FileName)
	info, err := os.Stat(filePath)
	if os.IsNotExist(err) {
		return true
	}
	if strings.HasSuffix(filePath, ".nfo") && !nfo {
		return false
	}
	return file.FileSize != info.Size() || file.Timestamp > info.ModTime().Unix()
}

// downloadFile downloads a file from the given URL and saves it to the media directory.
func downloadFile(file Metadata, client *http.Client, media string) {
	req, err := http.NewRequest("GET", file.URL, nil)
	if err != nil {
		log.Printf("[ERROR] Download exception for %s: %v", file.FileName, err)
		return
	}
	req.Header.Set("User-Agent", GlobalUserAgent)

	resp, err := client.Do(req)
	if err != nil {
		log.Printf("[ERROR] Download exception for %s: %v", file.FileName, err)
		return
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		log.Printf("[ERROR] Failed to download: %s [Response code: %d]", file.FileName, resp.StatusCode)
		return
	}

	filePath := filepath.Join(media, strings.TrimLeft(file.FileName, "/"))
	if err := os.MkdirAll(filepath.Dir(filePath), dirPerm); err != nil {
		log.Printf("[ERROR] Failed to create directories for %s: %v", filePath, err)
		return
	}

	out, err := os.Create(filePath)
	if err != nil {
		log.Printf("[ERROR] Failed to create file %s: %v", filePath, err)
		return
	}
	defer out.Close()

	if _, err := io.Copy(out, resp.Body); err != nil {
		log.Printf("[ERROR] Failed to write file %s: %v", filePath, err)
		return
	}

	if err := os.Chmod(filePath, filePerm); err != nil {
		log.Printf("[ERROR] Failed to set permissions for %s: %v", filePath, err)
	}

	log.Printf("[INFO] Downloaded: %s", file.FileName)
}

// downloadFiles concurrently downloads files that need to be updated.
func downloadFiles(files []Metadata, client *http.Client, media string, nfo bool) {
	var wg sync.WaitGroup
	numWorkers := runtime.NumCPU() * 4            // Set the number of workers to 4 times the number of CPU cores
	workerPool := make(chan struct{}, numWorkers) // Create a buffered channel to limit the number of concurrent workers

	for _, file := range files {
		if needDownload(file, media, nfo) {
			wg.Add(1)
			workerPool <- struct{}{} // Acquire a worker slot
			go func(f Metadata) {
				defer wg.Done()
				defer func() { <-workerPool }() // Release the worker slot

				downloadFile(f, client, media)
			}(file)
		}
	}
	wg.Wait()
}

// createTable creates the files table in the database if it doesn't exist.
func createTable(db *sql.DB) error {
	sqlStmt := `CREATE TABLE IF NOT EXISTS files (
		filename TEXT PRIMARY KEY,
		timestamp INTEGER,
		filesize INTEGER
	);`
	_, err := db.Exec(sqlStmt)
	return err
}

// insertFiles inserts or replaces file records in the database.
func insertFiles(db *sql.DB, items []Metadata) error {
	tx, err := db.Begin()
	if err != nil {
		return err
	}
	defer tx.Rollback() // Ensure rollback in case of error

	stmt, err := tx.Prepare("INSERT OR REPLACE INTO files(filename, timestamp, filesize) VALUES (?, ?, ?)")
	if err != nil {
		return err
	}
	defer stmt.Close()

	for _, item := range items {
		if _, err := stmt.Exec(item.FileName, item.Timestamp, item.FileSize); err != nil {
			return err
		}
	}
	return tx.Commit()
}

// processFolder processes a folder and returns a list of FileRecords.
func processFolder(folder, media string) ([]Metadata, error) {
	var items []Metadata
	err := filepath.Walk(folder, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if info.IsDir() {
			for _, d := range sFolder {
				if info.Name() == d {
					return filepath.SkipDir
				}
			}
			return nil
		}
		base := filepath.Base(path)
		if strings.HasPrefix(base, ".") {
			return nil
		}
		for _, ext := range sExt {
			if strings.HasSuffix(strings.ToLower(base), ext) {
				return nil
			}
		}
		rel, err := filepath.Rel(media, path)
		if err != nil {
			log.Printf("[ERROR] Failed to get relative path for %s: %v", path, err)
			return nil
		}
		items = append(items, Metadata{FileName: rel})
		return nil
	})
	return items, err
}

// removeEmptyFolders removes empty folders that are not in the sFolder list.
func removeEmptyFolders(paths []string, media string) {
	for _, p := range paths {
		folder := filepath.Join(media, p)
		filepath.Walk(folder, func(path string, info os.FileInfo, err error) error {
			if err != nil {
				return nil
			}
			if info.IsDir() {
				entries, err := os.ReadDir(path)
				if err == nil && len(entries) == 0 {
					base := filepath.Base(path)
					skip := false
					for _, d := range sFolder {
						if base == d {
							skip = true
							break
						}
					}
					if !skip {
						if err := os.Remove(path); err != nil {
							log.Printf("[ERROR] Failed to delete folder %s: %v", path, err)
						}
					}
				}
			}
			return nil
		})
	}
}

// generateLocalDB generates a local database by processing specified folders.
func generateLocalDB(dbPath, media string, paths []string) error {
	log.Printf("[INFO] Generating local DB... It takes time depends on the DiskI/O performance... DO NOT quit...")
	db, err := sql.Open("sqlite3", dbPath)
	if err != nil {
		return err
	}
	defer db.Close()

	if err := createTable(db); err != nil {
		return err
	}

	for _, p := range paths {
		folder := filepath.Join(media, p)
		if err := os.MkdirAll(folder, dirPerm); err != nil {
			return err
		}
		log.Printf("[INFO] Processing %s", folder)
		items, err := processFolder(folder, media)
		if err != nil {
			log.Printf("[ERROR] Failed to process folder %s: %v", folder, err)
			continue
		}
		if err := insertFiles(db, items); err != nil {
			log.Printf("[ERROR] Failed to insert files from folder %s: %v", folder, err)
			continue
		}
	}

	count, err := getTotalItemsCount(db)
	if err != nil {
		return err
	}
	log.Printf("[INFO] There are %d files on the local disk", count)
	return nil
}

// getTotalItemsCount returns the total number of files in the database.
func getTotalItemsCount(db *sql.DB) (int, error) {
	var count int
	row := db.QueryRow("SELECT COUNT(*) FROM files")
	err := row.Scan(&count)
	return count, err
}

// crawlOne crawls a single URL and processes files and directories.
func crawlOne(urlStr string, client *http.Client, media string, nfo bool, paths []string, db *sql.DB) ([]string, error) {
	parsedURL, err := url.Parse(urlStr)
	if err != nil {
		return nil, err
	}
	if parsedURL.Path == "/" {
		var directories []string
		for _, p := range paths {
			directories = append(directories, resolveURL(urlStr, p))
		}
		return directories, nil
	}
	files, directories, err := parseURL(urlStr, client)
	if err != nil {
		log.Printf("[ERROR] Failed to read document from file server: %v", err)
		return nil, err
	}
	if len(files) > 0 && media != "" {
		downloadFiles(files, client, media, nfo)
	}
	if db != nil && len(files) > 0 {
		if err := insertFiles(db, files); err != nil {
			log.Printf("[ERROR] Failed to insert files into DB: %v", err)
			return nil, err
		}
	}
	return directories, nil
}

// bulkCrawlAndWrite recursively crawls directories and processes files.
func bulkCrawlAndWrite(urlStr string, client *http.Client, media string, nfo bool, paths []string, db *sql.DB, depth int) {
	directories, err := crawlOne(urlStr, client, media, nfo, paths, db)
	if err != nil {
		log.Printf("[ERROR] Failed to crawl %s: %v", urlStr, err)
		return
	}
	for _, dir := range directories {
		bulkCrawlAndWrite(dir, client, media, nfo, paths, db, depth+1)
	}
}

// compareDatabases compares two databases and returns a list of differing filenames.
func compareDatabases(localdbPath, remotedbPath string) ([]string, error) {
	localdb, err := sql.Open("sqlite3", localdbPath)
	if err != nil {
		return nil, err
	}
	defer localdb.Close()

	remotedb, err := sql.Open("sqlite3", remotedbPath)
	if err != nil {
		return nil, err
	}
	defer remotedb.Close()

	localFilenames, err := getFilenames(localdb)
	if err != nil {
		return nil, err
	}

	remoteFilenames, err := getFilenames(remotedb)
	if err != nil {
		return nil, err
	}

	var diff []string
	for fname := range localFilenames {
		if _, exists := remoteFilenames[fname]; !exists {
			diff = append(diff, fname)
		}
	}
	return diff, nil
}

// getFilenames retrieves all filenames from a database.
func getFilenames(db *sql.DB) (map[string]bool, error) {
	rows, err := db.Query("SELECT filename FROM files")
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	filenames := make(map[string]bool)
	for rows.Next() {
		var filename string
		if err := rows.Scan(&filename); err != nil {
			return nil, err
		}
		filenames[filename] = true
	}
	return filenames, nil
}

// purgeRemovedFiles removes files from the media directory that are not in the remote database.
func purgeRemovedFiles(localdbPath, remotedbPath, media string) {
	diff, err := compareDatabases(localdbPath, remotedbPath)
	if err != nil {
		log.Printf("[ERROR] Failed to compare databases: %v", err)
		return
	}
	for _, file := range diff {
		if err := os.Remove(filepath.Join(media, file)); err != nil {
			log.Printf("[ERROR] Failed to remove %s: %v", file, err)
		}
	}
}
